{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook evaluates and number of algorithms onto the prediction task thickness grid to latest diagnose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.decomposition import PCA \n",
    "from sklearn.pipeline import Pipeline \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.externals import joblib \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm \n",
    "from sklearn import tree\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "path = r'C:\\Users\\s-oholmber\\OCT_depth_project\\data\\ML_prediction_task_1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Nan values found in full data are: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['PatientID_DB', 'C0', 'I1', 'I2', 'N1', 'N2', 'S1', 'S2', 'T1', 'T2',\n",
       "       'DKAT'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load data process data\n",
    "X_path =  os.path.join(path , \"X.csv\")\n",
    "X = pd.read_csv(X_path).drop(columns = [\"series_ID\"])\n",
    "\n",
    "Y_path =  os.path.join(path , \"Y.csv\")\n",
    "Y = pd.read_csv(Y_path).drop(columns = [\"Unnamed: 0\"]).drop_duplicates()\n",
    "Y = Y.rename(columns={'Katalog_des_Diagnosecode_DKAT': 'DKAT'})\n",
    "\n",
    "#X.shape, X[X.isnan()].shape\n",
    "number_of_record_with_missing_values = sum(X.isnull().any(axis=1))\n",
    "indexes_with_Nan = ~X.isnull().any(axis=1)\n",
    "indexes = indexes_with_Nan[indexes_with_Nan != False]\n",
    "\n",
    "#remove Nans\n",
    "X = X[indexes_with_Nan]\n",
    "Y['P_ID_DB'].head(), X['PatientID_DB'].head()\n",
    "\n",
    "full_data = X.merge(Y, left_on = \"PatientID_DB\",right_on = \"P_ID_DB\", how = \"left\").dropna()\n",
    "full_data = full_data.drop(['P_ID_DB'], axis = 1)\n",
    "print(\"Number of Nan values found in full data are: {}\".format(np.sum(full_data.isnull().any(axis=1))))\n",
    "indexes_with_Nan = full_data.isnull().any(axis=1)\n",
    "#print(\"the records without diagnosis are: {}\".format(full_data[indexes_with_Nan]))\n",
    "full_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct some pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_lr = Pipeline([('scl', StandardScaler()),\n",
    "            ('clf', LogisticRegression(random_state=42))])\n",
    "\n",
    "pipe_lr_pca = Pipeline([('scl', StandardScaler()),\n",
    "            ('pca', PCA(n_components=2)),\n",
    "            ('clf', LogisticRegression(random_state=42))])\n",
    "\n",
    "pipe_rf = Pipeline([('scl', StandardScaler()),\n",
    "            ('clf', RandomForestClassifier(random_state=42))])\n",
    "\n",
    "pipe_rf_pca = Pipeline([('scl', StandardScaler()),\n",
    "            ('pca', PCA(n_components=2)),\n",
    "            ('clf', RandomForestClassifier(random_state=42))])\n",
    "\n",
    "pipe_svm = Pipeline([('scl', StandardScaler()),\n",
    "            ('clf', svm.SVC(random_state=42))])\n",
    "\n",
    "pipe_svm_pca = Pipeline([('scl', StandardScaler()),\n",
    "            ('pca', PCA(n_components=2)),\n",
    "            ('clf', svm.SVC(random_state=42))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set grid params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_range = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "param_range_fl = [1.0, 0.5, 0.1]\n",
    "\n",
    "grid_params_lr = [{'clf__penalty': ['l1', 'l2'],\n",
    "        'clf__C': param_range_fl,\n",
    "        'clf__solver': ['liblinear']}] \n",
    "\n",
    "grid_params_rf = [{'clf__criterion': ['gini', 'entropy'],\n",
    "        'clf__min_samples_leaf': param_range,\n",
    "        'clf__max_depth': param_range,\n",
    "        'clf__min_samples_split': param_range[1:]}]\n",
    "\n",
    "grid_params_svm = [{'clf__kernel': ['linear', 'rbf'], \n",
    "        'clf__C': param_range}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct grid searches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = -1\n",
    "\n",
    "gs_lr = GridSearchCV(estimator=pipe_lr,\n",
    "            param_grid=grid_params_lr,\n",
    "            scoring='accuracy',\n",
    "            cv=10) \n",
    "\n",
    "gs_lr_pca = GridSearchCV(estimator=pipe_lr_pca,\n",
    "            param_grid=grid_params_lr,\n",
    "            scoring='accuracy',\n",
    "            cv=10)\n",
    "\n",
    "gs_rf = GridSearchCV(estimator=pipe_rf,\n",
    "            param_grid=grid_params_rf,\n",
    "            scoring='accuracy',\n",
    "            cv=10, \n",
    "            n_jobs=jobs)\n",
    "\n",
    "gs_rf_pca = GridSearchCV(estimator=pipe_rf_pca,\n",
    "            param_grid=grid_params_rf,\n",
    "            scoring='accuracy',\n",
    "            cv=10, \n",
    "            n_jobs=jobs)\n",
    "\n",
    "gs_svm = GridSearchCV(estimator=pipe_svm,\n",
    "            param_grid=grid_params_svm,\n",
    "            scoring='accuracy',\n",
    "            cv=10,\n",
    "            n_jobs=jobs)\n",
    "\n",
    "gs_svm_pca = GridSearchCV(estimator=pipe_svm_pca,\n",
    "            param_grid=grid_params_svm,\n",
    "            scoring='accuracy',\n",
    "            cv=10,\n",
    "            n_jobs=jobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the grid search objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing model optimizations...\n",
      "\n",
      "Estimator: Logistic Regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s-oholmber\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:605: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'clf__C': 0.1, 'clf__penalty': 'l1', 'clf__solver': 'liblinear'}\n",
      "Best training accuracy: 0.231\n",
      "Test set accuracy score for best params: 0.236 \n",
      "\n",
      "Estimator: Logistic Regression w/PCA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s-oholmber\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:605: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'clf__C': 0.5, 'clf__penalty': 'l1', 'clf__solver': 'liblinear'}\n",
      "Best training accuracy: 0.202\n",
      "Test set accuracy score for best params: 0.211 \n",
      "\n",
      "Estimator: Random Forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s-oholmber\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:605: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'clf__criterion': 'entropy', 'clf__max_depth': 10, 'clf__min_samples_leaf': 1, 'clf__min_samples_split': 2}\n",
      "Best training accuracy: 0.426\n",
      "Test set accuracy score for best params: 0.445 \n",
      "\n",
      "Estimator: Random Forest w/PCA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s-oholmber\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:605: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'clf__criterion': 'gini', 'clf__max_depth': 8, 'clf__min_samples_leaf': 2, 'clf__min_samples_split': 7}\n",
      "Best training accuracy: 0.259\n",
      "Test set accuracy score for best params: 0.279 \n",
      "\n",
      "Estimator: Support Vector Machine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s-oholmber\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:605: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'clf__C': 10, 'clf__kernel': 'rbf'}\n",
      "Best training accuracy: 0.342\n",
      "Test set accuracy score for best params: 0.333 \n",
      "\n",
      "Estimator: Support Vector Machine w/PCA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s-oholmber\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:605: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'clf__C': 7, 'clf__kernel': 'rbf'}\n",
      "Best training accuracy: 0.247\n",
      "Test set accuracy score for best params: 0.257 \n",
      "\n",
      "Classifier with best test set accuracy: Random Forest\n"
     ]
    }
   ],
   "source": [
    "#extract features and labels for train and test\n",
    "X = full_data.loc[:, 'C0':'T2']\n",
    "Y = full_data.loc[:, 'DKAT']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# List of pipelines for ease of iteration\n",
    "grids = [gs_lr, gs_lr_pca, gs_rf, gs_rf_pca, gs_svm, gs_svm_pca]\n",
    "\n",
    "# Dictionary of pipelines and classifier types for ease of reference\n",
    "grid_dict = {0: 'Logistic Regression', 1: 'Logistic Regression w/PCA', \n",
    "        2: 'Random Forest', 3: 'Random Forest w/PCA', \n",
    "        4: 'Support Vector Machine', 5: 'Support Vector Machine w/PCA'}\n",
    "\n",
    "# Fit the grid search objects\n",
    "print('Performing model optimizations...')\n",
    "best_acc = 0.0\n",
    "best_clf = 0\n",
    "best_gs = ''\n",
    "for idx, gs in enumerate(grids):\n",
    "    print('\\nEstimator: %s' % grid_dict[idx])\n",
    "    # Fit grid search\t\n",
    "    gs.fit(X_train, y_train)\n",
    "    # Best params\n",
    "    print('Best params: %s' % gs.best_params_)\n",
    "    # Best training data accuracy\n",
    "    print('Best training accuracy: %.3f' % gs.best_score_)\n",
    "    # Predict on test data with best params\n",
    "    y_pred = gs.predict(X_test)\n",
    "    # Test data accuracy of model with best params\n",
    "    print('Test set accuracy score for best params: %.3f ' % accuracy_score(y_test, y_pred))\n",
    "    # Track best (highest test accuracy) model\n",
    "    if accuracy_score(y_test, y_pred) > best_acc:\n",
    "        best_acc = accuracy_score(y_test, y_pred)\n",
    "        best_gs = gs\n",
    "        best_clf = idx\n",
    "print('\\nClassifier with best test set accuracy: %s' % grid_dict[best_clf])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Decision Tree pipeline to file\n"
     ]
    }
   ],
   "source": [
    "# Save pipeline to file \n",
    "problem_path = r\"C:\\Users\\s-oholmber\\OCT_depth_project\\prediction_problem1\"\n",
    "write_loc = os.path.join(problem_path, 'best_pipeline.pkl')\n",
    "joblib.dump(best_pipe, write_loc, compress=1) \n",
    "print('Saved %s pipeline to file' % pipe_dict[best_clf]) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
